APP_VERSION=1

# path is relative to duelgame source folder
DATABASE_PATH=../../data/database.sqlite
DEFAULT_MODEL_FILE_PATH=default_model.json

MAX_TURNS_PER_GAME=50
SAMPLES_COUNT_PER_RUN=10000

# policies data count distribution [Aggressive, Defensive, Balanced/Tactical, Opportunist, Healer/Sustain, Random-Biased]
DUMMY_PLAYER_POLICIES_DATA_DISTRIBUTION_IN_RUN=[0.25, 0.2, 0.15, 0.15, 0.15, 0.1]

# Policy data samples distribution - each policy has a list of opponent policies and a list of corresponding distributions in its data

AGGRESSIVE_OPPONENTS=["Defensive", "Healer", "Opportunist", "Balanced", "Aggressive"]
AGGRESSIVE_DISTRIBUTION=[0.25, 0.25, 0.25, 0.15, 0.1]

Defensive_OPPONENTS=["Aggressive", "Opportunist", "Balanced", "RandomBiased", "Defensive"]
Defensive_DISTRIBUTION=[0.3, 0.2, 0.2, 0.2, 0.1]

Balanced_OPPONENTS=["Balanced", "Aggressive", "Opportunist", "Defensive", "Healer"]
Balanced_DISTRIBUTION=[0.3, 0.2, 0.2, 0.2, 0.1]

Healer_OPPONENTS=["Aggressive", "Balanced", "Opportunist", "Defensive", "Healer"]
Healer_DISTRIBUTION=[0.3, 0.2, 0.2, 0.2, 0.1]

Opportunist_OPPONENTS=["Aggressive", "Balanced", "Opportunist", "Defensive"]
Opportunist_DISTRIBUTION=[0.3, 0.3, 0.2, 0.2]

RandomBiased_OPPONENTS=["Aggressive", "Defensive", "Healer", "Balanced", "Opportunist", "RandomBiased"]
RandomBiased_DISTRIBUTION=[0.166, 0.166, 0.166, 0.166, 0.166, 0.166]

# Policy behavior-specific variables

# ============================================================================
#   Aggressive Archtype Parameters
# ============================================================================
AGGRESSIVE_EPSILON=0.1
AGGRESSIVE_ATTACK_BIAS=0.7
AGGRESSIVE_HEAL_THRESHOLD=40
AGGRESSIVE_ATTACK_THREAT_THRESHOLD=0.6
AGGRESSIVE_ATTACK_THREAT_HISTORY_LENGTH=5

# ============================================================================
#   Defensive Archtype Parameters
# ============================================================================
DEFENSIVE_EPSILON=0.1
DEFENSIVE_ATTACK_PROB_OPP_HP_LOW=0.6
DEFENSIVE_OPP_HP_THRESHOLD=30
DEFENSIVE_HEAL_BIAS=0.6
DEFENSIVE_DEFENSE_BIAS=0.7
DEFENSIVE_ATTACK_THREAT_THRESHOLD=0.4
DEFENSIVE_ATTACK_THREAT_HISTORY_LENGTH=5
DEFENSIVE_ATTACK_START_TURN_THRESHOLD=5

# ============================================================================
#   Balanced Archtype Parameters
# ============================================================================
BALANCED_EPSILON=0.1
BALANCED_DOMINATION_MARGIN=30
BALANCED_DESPERATION_MARGIN=-20

# ============================================================================
#   Healer Archtype Parameters
# ============================================================================
HEALER_EPSILON=0.1
HEALER_HEAL_THRESHOLD=80
HEALER_HEAL_BIAS=0.8
HEALER_ATTACK_PROB=0.3

# ============================================================================
#   Opportunist Archtype Parameters
# ============================================================================
OPPORTUNIST_EPSILON=0.1
OPPORTUNIST_DECISION_THRESHOLD=0.5
OPPORTUNIST_BASE_TURN_NUMBER=5
OPPORTUNIST_HEAL_THRESHOLD=35
OPPORTUNIST_HEAL_BIAS=0.85

# ============================================================================
#   Random-Biased Archtype Parameters
# ============================================================================
RANDOM_BIASED_W_ATTACK=0.25
RANDOM_BIASED_W_DEFENSE=0.25
RANDOM_BIASED_W_DODGE=0.25
RANDOM_BIASED_W_HEAL=0.25



# ----------------------------------------------------------------------------
# MODEL TRAINING CONFIGURATION
# ----------------------------------------------------------------------------
# TRAIN_RUN_ID=1                    # Run ID to train model for
TRAIN_TEST_SIZE=0.2              # Proportion of data for testing
TRAIN_RANDOM_STATE=42            # Random seed for reproducibility

# ----------------------------------------------------------------------------
# LOGISTIC REGRESSION HYPERPARAMETERS
# ----------------------------------------------------------------------------
LR_MAX_ITER=1000                 # Maximum iterations for solver
LR_SOLVER=lbfgs                 # Solver type (lbfgs, liblinear, saga, etc.)
LR_MULTI_CLASS=auto             # Multi-class strategy (auto, ovr, multinomial)
LR_C=1.0                        # Inverse regularization strength
LR_PENALTY=l2                   # Penalty norm (l1, l2, elasticnet, none)
LR_TOL=0.0001                  # Tolerance for stopping criteria
LR_FIT_INTERCEPT=True          # Whether to fit intercept
LR_WARM_START=False            # Reuse previous solution as initialization
LR_N_JOBS=None                 # Number of CPU cores to use

# ----------------------------------------------------------------------------
# DATA PROCESSING CONFIGURATION
# ----------------------------------------------------------------------------
MIN_SAMPLES_PER_CLASS=1         # Minimum samples required per class
STRATIFY_SPLIT=True            # Use stratified split
SHUFFLE_SPLIT=True            # Shuffle data before splitting

# ============================================================================